{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af153024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from MySequencial import MySequencial\n",
    "from DenseLayer import DenseLayer\n",
    "import pandas as pd\n",
    "from LossFunctions import setLossFunction, binaryCrossentropyLoss, sparseCategoricalCrossEntropyLoss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f397addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wheat-seeds.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8946423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,-1] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e687cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = MySequencial([\n",
    "    DenseLayer(7, activation=\"linear\"), \n",
    "    DenseLayer(8, activation='sigmoid'),\n",
    "    DenseLayer(8, activation='sigmoid'),\n",
    "    DenseLayer(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae98d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d20deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9931d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:int(len(data) * 0.75),:]\n",
    "data_val = data[int(len(data) * 0.75):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2913c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data[:, :-1]\n",
    "# y_train = data[:, -1]\n",
    "# y_pred = myModel.predict(X_train)\n",
    "# y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "# m = y_train.shape[0]\n",
    "\n",
    "# y_pred[np.arange(m), y_train.astype(int)]\n",
    "\n",
    "# loss = -1/m * np.sum(np.log(y_pred[np.arange(m), y_train]))\n",
    "# return loss\n",
    "\n",
    "# def sparse_categorical_cross_entropy_loss(y_true, y_pred):\n",
    "#     # Assurez-vous que les prédictions ne sont pas nulles\n",
    "#     y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "#     # Nombre d'échantillons\n",
    "#     m = y_true.shape[0]\n",
    "    \n",
    "#     # Extraire les probabilités prédites pour les classes correctes\n",
    "#     # Utilisez y_true comme indice pour sélectionner la probabilité prédite pour chaque exemple\n",
    "#     correct_probs = y_pred[np.arange(m), y_true]\n",
    "    \n",
    "#     # Calcul de la perte\n",
    "#     loss = -1/m * np.sum(np.log(correct_probs))\n",
    "    \n",
    "#     return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac433a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 20/20 - accuracy: 87.9, loss:0.3, val accuracy: 92.45, val loss: 0.238\n",
      "epoch 1 : 20/20 - accuracy: 91.08, loss:0.289, val accuracy: 94.34, val loss: 0.231\n",
      "epoch 2 : 20/20 - accuracy: 87.9, loss:0.304, val accuracy: 92.45, val loss: 0.246\n",
      "epoch 3 : 20/20 - accuracy: 92.36, loss:0.288, val accuracy: 94.34, val loss: 0.227\n",
      "epoch 4 : 20/20 - accuracy: 89.81, loss:0.291, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 5 : 20/20 - accuracy: 92.36, loss:0.287, val accuracy: 94.34, val loss: 0.227\n",
      "epoch 6 : 20/20 - accuracy: 89.17, loss:0.303, val accuracy: 94.34, val loss: 0.248\n",
      "epoch 7 : 20/20 - accuracy: 89.81, loss:0.291, val accuracy: 96.23, val loss: 0.222\n",
      "epoch 8 : 20/20 - accuracy: 88.54, loss:0.299, val accuracy: 94.34, val loss: 0.247\n",
      "epoch 9 : 20/20 - accuracy: 87.9, loss:0.298, val accuracy: 92.45, val loss: 0.233\n",
      "epoch 10 : 20/20 - accuracy: 89.81, loss:0.292, val accuracy: 96.23, val loss: 0.226\n",
      "epoch 11 : 20/20 - accuracy: 89.17, loss:0.288, val accuracy: 94.34, val loss: 0.235\n",
      "epoch 12 : 20/20 - accuracy: 89.17, loss:0.287, val accuracy: 94.34, val loss: 0.231\n",
      "epoch 13 : 20/20 - accuracy: 91.72, loss:0.292, val accuracy: 96.23, val loss: 0.229\n",
      "epoch 14 : 20/20 - accuracy: 90.45, loss:0.287, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 15 : 20/20 - accuracy: 92.36, loss:0.285, val accuracy: 94.34, val loss: 0.223\n",
      "epoch 16 : 20/20 - accuracy: 85.35, loss:0.305, val accuracy: 92.45, val loss: 0.24\n",
      "epoch 17 : 20/20 - accuracy: 89.81, loss:0.292, val accuracy: 96.23, val loss: 0.24\n",
      "epoch 18 : 20/20 - accuracy: 88.54, loss:0.311, val accuracy: 92.45, val loss: 0.253\n",
      "epoch 19 : 20/20 - accuracy: 91.08, loss:0.287, val accuracy: 96.23, val loss: 0.226\n",
      "epoch 20 : 20/20 - accuracy: 89.17, loss:0.289, val accuracy: 94.34, val loss: 0.217\n",
      "epoch 21 : 20/20 - accuracy: 87.9, loss:0.298, val accuracy: 94.34, val loss: 0.226\n",
      "epoch 22 : 20/20 - accuracy: 88.54, loss:0.287, val accuracy: 94.34, val loss: 0.222\n",
      "epoch 23 : 20/20 - accuracy: 87.9, loss:0.293, val accuracy: 96.23, val loss: 0.221\n",
      "epoch 24 : 20/20 - accuracy: 92.36, loss:0.283, val accuracy: 94.34, val loss: 0.222\n",
      "epoch 25 : 20/20 - accuracy: 88.54, loss:0.303, val accuracy: 92.45, val loss: 0.232\n",
      "epoch 26 : 20/20 - accuracy: 88.54, loss:0.293, val accuracy: 92.45, val loss: 0.231\n",
      "epoch 27 : 20/20 - accuracy: 89.17, loss:0.304, val accuracy: 92.45, val loss: 0.249\n",
      "epoch 28 : 20/20 - accuracy: 88.54, loss:0.284, val accuracy: 94.34, val loss: 0.229\n",
      "epoch 29 : 20/20 - accuracy: 90.45, loss:0.283, val accuracy: 94.34, val loss: 0.224\n",
      "epoch 30 : 20/20 - accuracy: 87.9, loss:0.288, val accuracy: 94.34, val loss: 0.238\n",
      "epoch 31 : 20/20 - accuracy: 89.17, loss:0.285, val accuracy: 94.34, val loss: 0.214\n",
      "epoch 32 : 20/20 - accuracy: 89.81, loss:0.286, val accuracy: 92.45, val loss: 0.229\n",
      "epoch 33 : 20/20 - accuracy: 91.08, loss:0.282, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 34 : 20/20 - accuracy: 86.62, loss:0.299, val accuracy: 94.34, val loss: 0.23\n",
      "epoch 35 : 20/20 - accuracy: 89.81, loss:0.288, val accuracy: 96.23, val loss: 0.231\n",
      "epoch 36 : 20/20 - accuracy: 88.54, loss:0.293, val accuracy: 96.23, val loss: 0.243\n",
      "epoch 37 : 20/20 - accuracy: 90.45, loss:0.281, val accuracy: 94.34, val loss: 0.224\n",
      "epoch 38 : 20/20 - accuracy: 91.72, loss:0.287, val accuracy: 96.23, val loss: 0.224\n",
      "epoch 39 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 94.34, val loss: 0.215\n",
      "epoch 40 : 20/20 - accuracy: 89.81, loss:0.287, val accuracy: 96.23, val loss: 0.22\n",
      "epoch 41 : 20/20 - accuracy: 86.62, loss:0.296, val accuracy: 92.45, val loss: 0.233\n",
      "epoch 42 : 20/20 - accuracy: 88.54, loss:0.292, val accuracy: 96.23, val loss: 0.241\n",
      "epoch 43 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 96.23, val loss: 0.216\n",
      "epoch 44 : 20/20 - accuracy: 92.36, loss:0.279, val accuracy: 94.34, val loss: 0.217\n",
      "epoch 45 : 20/20 - accuracy: 90.45, loss:0.285, val accuracy: 92.45, val loss: 0.225\n",
      "epoch 46 : 20/20 - accuracy: 90.45, loss:0.29, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 47 : 20/20 - accuracy: 90.45, loss:0.28, val accuracy: 94.34, val loss: 0.223\n",
      "epoch 48 : 20/20 - accuracy: 91.72, loss:0.279, val accuracy: 94.34, val loss: 0.22\n",
      "epoch 49 : 20/20 - accuracy: 92.36, loss:0.279, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 50 : 20/20 - accuracy: 91.08, loss:0.278, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 51 : 20/20 - accuracy: 89.81, loss:0.279, val accuracy: 94.34, val loss: 0.223\n",
      "epoch 52 : 20/20 - accuracy: 90.45, loss:0.279, val accuracy: 94.34, val loss: 0.222\n",
      "epoch 53 : 20/20 - accuracy: 90.45, loss:0.282, val accuracy: 92.45, val loss: 0.222\n",
      "epoch 54 : 20/20 - accuracy: 89.81, loss:0.28, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 55 : 20/20 - accuracy: 90.45, loss:0.28, val accuracy: 94.34, val loss: 0.223\n",
      "epoch 56 : 20/20 - accuracy: 90.45, loss:0.282, val accuracy: 92.45, val loss: 0.222\n",
      "epoch 57 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 96.23, val loss: 0.216\n",
      "epoch 58 : 20/20 - accuracy: 86.62, loss:0.295, val accuracy: 92.45, val loss: 0.235\n",
      "epoch 59 : 20/20 - accuracy: 89.17, loss:0.285, val accuracy: 92.45, val loss: 0.231\n",
      "epoch 60 : 20/20 - accuracy: 90.45, loss:0.278, val accuracy: 94.34, val loss: 0.209\n",
      "epoch 61 : 20/20 - accuracy: 89.17, loss:0.279, val accuracy: 94.34, val loss: 0.213\n",
      "epoch 62 : 20/20 - accuracy: 90.45, loss:0.278, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 63 : 20/20 - accuracy: 91.72, loss:0.277, val accuracy: 94.34, val loss: 0.213\n",
      "epoch 64 : 20/20 - accuracy: 92.36, loss:0.276, val accuracy: 94.34, val loss: 0.213\n",
      "epoch 65 : 20/20 - accuracy: 91.08, loss:0.276, val accuracy: 94.34, val loss: 0.21\n",
      "epoch 66 : 20/20 - accuracy: 90.45, loss:0.282, val accuracy: 96.23, val loss: 0.216\n",
      "epoch 67 : 20/20 - accuracy: 91.08, loss:0.276, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 68 : 20/20 - accuracy: 90.45, loss:0.276, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 69 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 96.23, val loss: 0.207\n",
      "epoch 70 : 20/20 - accuracy: 91.08, loss:0.275, val accuracy: 94.34, val loss: 0.21\n",
      "epoch 71 : 20/20 - accuracy: 90.45, loss:0.282, val accuracy: 92.45, val loss: 0.223\n",
      "epoch 72 : 20/20 - accuracy: 91.72, loss:0.276, val accuracy: 94.34, val loss: 0.218\n",
      "epoch 73 : 20/20 - accuracy: 91.72, loss:0.279, val accuracy: 96.23, val loss: 0.217\n",
      "epoch 74 : 20/20 - accuracy: 89.81, loss:0.285, val accuracy: 96.23, val loss: 0.215\n",
      "epoch 75 : 20/20 - accuracy: 89.17, loss:0.28, val accuracy: 92.45, val loss: 0.217\n",
      "epoch 76 : 20/20 - accuracy: 89.81, loss:0.276, val accuracy: 94.34, val loss: 0.214\n",
      "epoch 77 : 20/20 - accuracy: 86.62, loss:0.299, val accuracy: 92.45, val loss: 0.238\n",
      "epoch 78 : 20/20 - accuracy: 86.62, loss:0.29, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 79 : 20/20 - accuracy: 89.81, loss:0.279, val accuracy: 96.23, val loss: 0.211\n",
      "epoch 80 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 96.23, val loss: 0.226\n",
      "epoch 81 : 20/20 - accuracy: 89.81, loss:0.274, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 82 : 20/20 - accuracy: 89.17, loss:0.275, val accuracy: 94.34, val loss: 0.209\n",
      "epoch 83 : 20/20 - accuracy: 89.17, loss:0.276, val accuracy: 92.45, val loss: 0.214\n",
      "epoch 84 : 20/20 - accuracy: 88.54, loss:0.277, val accuracy: 94.34, val loss: 0.206\n",
      "epoch 85 : 20/20 - accuracy: 91.72, loss:0.277, val accuracy: 96.23, val loss: 0.212\n",
      "epoch 86 : 20/20 - accuracy: 92.36, loss:0.272, val accuracy: 94.34, val loss: 0.212\n",
      "epoch 87 : 20/20 - accuracy: 89.81, loss:0.281, val accuracy: 92.45, val loss: 0.224\n",
      "epoch 88 : 20/20 - accuracy: 87.26, loss:0.303, val accuracy: 92.45, val loss: 0.255\n",
      "epoch 89 : 20/20 - accuracy: 92.36, loss:0.272, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 90 : 20/20 - accuracy: 90.45, loss:0.272, val accuracy: 94.34, val loss: 0.206\n",
      "epoch 91 : 20/20 - accuracy: 90.45, loss:0.275, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 92 : 20/20 - accuracy: 89.81, loss:0.282, val accuracy: 96.23, val loss: 0.227\n",
      "epoch 93 : 20/20 - accuracy: 89.17, loss:0.277, val accuracy: 96.23, val loss: 0.202\n",
      "epoch 94 : 20/20 - accuracy: 90.45, loss:0.271, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 95 : 20/20 - accuracy: 91.08, loss:0.272, val accuracy: 94.34, val loss: 0.213\n",
      "epoch 96 : 20/20 - accuracy: 87.9, loss:0.281, val accuracy: 96.23, val loss: 0.204\n",
      "epoch 97 : 20/20 - accuracy: 90.45, loss:0.281, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 98 : 20/20 - accuracy: 89.17, loss:0.276, val accuracy: 94.34, val loss: 0.202\n",
      "epoch 99 : 20/20 - accuracy: 92.36, loss:0.27, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 100 : 20/20 - accuracy: 91.72, loss:0.275, val accuracy: 96.23, val loss: 0.211\n",
      "epoch 101 : 20/20 - accuracy: 91.08, loss:0.275, val accuracy: 96.23, val loss: 0.214\n",
      "epoch 102 : 20/20 - accuracy: 90.45, loss:0.27, val accuracy: 94.34, val loss: 0.212\n",
      "epoch 103 : 20/20 - accuracy: 91.08, loss:0.276, val accuracy: 96.23, val loss: 0.216\n",
      "epoch 104 : 20/20 - accuracy: 89.81, loss:0.27, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 105 : 20/20 - accuracy: 89.81, loss:0.287, val accuracy: 92.45, val loss: 0.219\n",
      "epoch 106 : 20/20 - accuracy: 91.08, loss:0.27, val accuracy: 94.34, val loss: 0.212\n",
      "epoch 107 : 20/20 - accuracy: 89.81, loss:0.269, val accuracy: 94.34, val loss: 0.205\n",
      "epoch 108 : 20/20 - accuracy: 91.72, loss:0.277, val accuracy: 96.23, val loss: 0.211\n",
      "epoch 109 : 20/20 - accuracy: 90.45, loss:0.273, val accuracy: 94.34, val loss: 0.219\n",
      "epoch 110 : 20/20 - accuracy: 92.36, loss:0.268, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 111 : 20/20 - accuracy: 89.81, loss:0.28, val accuracy: 92.45, val loss: 0.221\n",
      "epoch 112 : 20/20 - accuracy: 92.36, loss:0.268, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 113 : 20/20 - accuracy: 87.26, loss:0.312, val accuracy: 88.68, val loss: 0.254\n",
      "epoch 114 : 20/20 - accuracy: 90.45, loss:0.271, val accuracy: 92.45, val loss: 0.214\n",
      "epoch 115 : 20/20 - accuracy: 87.9, loss:0.279, val accuracy: 92.45, val loss: 0.213\n",
      "epoch 116 : 20/20 - accuracy: 89.81, loss:0.268, val accuracy: 94.34, val loss: 0.202\n",
      "epoch 117 : 20/20 - accuracy: 89.17, loss:0.269, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 118 : 20/20 - accuracy: 89.81, loss:0.27, val accuracy: 94.34, val loss: 0.213\n",
      "epoch 119 : 20/20 - accuracy: 92.36, loss:0.267, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 120 : 20/20 - accuracy: 90.45, loss:0.269, val accuracy: 94.34, val loss: 0.211\n",
      "epoch 121 : 20/20 - accuracy: 91.72, loss:0.269, val accuracy: 96.23, val loss: 0.206\n",
      "epoch 122 : 20/20 - accuracy: 90.45, loss:0.268, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 123 : 20/20 - accuracy: 87.26, loss:0.277, val accuracy: 94.34, val loss: 0.231\n",
      "epoch 124 : 20/20 - accuracy: 89.81, loss:0.268, val accuracy: 94.34, val loss: 0.21\n",
      "epoch 125 : 20/20 - accuracy: 89.81, loss:0.285, val accuracy: 94.34, val loss: 0.226\n",
      "epoch 126 : 20/20 - accuracy: 89.81, loss:0.27, val accuracy: 92.45, val loss: 0.207\n",
      "epoch 127 : 20/20 - accuracy: 85.35, loss:0.293, val accuracy: 94.34, val loss: 0.225\n",
      "epoch 128 : 20/20 - accuracy: 91.72, loss:0.274, val accuracy: 96.23, val loss: 0.209\n",
      "epoch 129 : 20/20 - accuracy: 89.81, loss:0.273, val accuracy: 96.23, val loss: 0.203\n",
      "epoch 130 : 20/20 - accuracy: 91.08, loss:0.27, val accuracy: 96.23, val loss: 0.213\n",
      "epoch 131 : 20/20 - accuracy: 90.45, loss:0.266, val accuracy: 94.34, val loss: 0.21\n",
      "epoch 132 : 20/20 - accuracy: 85.99, loss:0.286, val accuracy: 92.45, val loss: 0.222\n",
      "epoch 133 : 20/20 - accuracy: 91.72, loss:0.273, val accuracy: 96.23, val loss: 0.211\n",
      "epoch 134 : 20/20 - accuracy: 89.81, loss:0.278, val accuracy: 92.45, val loss: 0.216\n",
      "epoch 135 : 20/20 - accuracy: 92.36, loss:0.265, val accuracy: 94.34, val loss: 0.201\n",
      "epoch 136 : 20/20 - accuracy: 91.08, loss:0.265, val accuracy: 94.34, val loss: 0.198\n",
      "epoch 137 : 20/20 - accuracy: 89.81, loss:0.265, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 138 : 20/20 - accuracy: 87.9, loss:0.273, val accuracy: 94.34, val loss: 0.202\n",
      "epoch 139 : 20/20 - accuracy: 92.36, loss:0.264, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 140 : 20/20 - accuracy: 89.81, loss:0.267, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 141 : 20/20 - accuracy: 89.81, loss:0.27, val accuracy: 96.23, val loss: 0.201\n",
      "epoch 142 : 20/20 - accuracy: 91.08, loss:0.276, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 143 : 20/20 - accuracy: 91.72, loss:0.267, val accuracy: 96.23, val loss: 0.204\n",
      "epoch 144 : 20/20 - accuracy: 89.17, loss:0.267, val accuracy: 94.34, val loss: 0.215\n",
      "epoch 145 : 20/20 - accuracy: 91.72, loss:0.265, val accuracy: 94.34, val loss: 0.203\n",
      "epoch 146 : 20/20 - accuracy: 89.81, loss:0.266, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 147 : 20/20 - accuracy: 89.17, loss:0.267, val accuracy: 96.23, val loss: 0.193\n",
      "epoch 148 : 20/20 - accuracy: 90.45, loss:0.265, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 149 : 20/20 - accuracy: 89.81, loss:0.269, val accuracy: 96.23, val loss: 0.213\n",
      "epoch 150 : 20/20 - accuracy: 90.45, loss:0.263, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 151 : 20/20 - accuracy: 85.99, loss:0.289, val accuracy: 92.45, val loss: 0.225\n",
      "epoch 152 : 20/20 - accuracy: 91.72, loss:0.264, val accuracy: 94.34, val loss: 0.201\n",
      "epoch 153 : 20/20 - accuracy: 91.72, loss:0.263, val accuracy: 94.34, val loss: 0.199\n",
      "epoch 154 : 20/20 - accuracy: 91.72, loss:0.263, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 155 : 20/20 - accuracy: 92.36, loss:0.262, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 156 : 20/20 - accuracy: 91.08, loss:0.262, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 157 : 20/20 - accuracy: 89.81, loss:0.268, val accuracy: 96.23, val loss: 0.195\n",
      "epoch 158 : 20/20 - accuracy: 91.72, loss:0.262, val accuracy: 94.34, val loss: 0.201\n",
      "epoch 159 : 20/20 - accuracy: 89.17, loss:0.268, val accuracy: 96.23, val loss: 0.192\n",
      "epoch 160 : 20/20 - accuracy: 91.08, loss:0.277, val accuracy: 94.34, val loss: 0.216\n",
      "epoch 161 : 20/20 - accuracy: 89.81, loss:0.265, val accuracy: 92.45, val loss: 0.208\n",
      "epoch 162 : 20/20 - accuracy: 88.54, loss:0.266, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 163 : 20/20 - accuracy: 91.08, loss:0.263, val accuracy: 94.34, val loss: 0.203\n",
      "epoch 164 : 20/20 - accuracy: 90.45, loss:0.261, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 165 : 20/20 - accuracy: 89.81, loss:0.277, val accuracy: 94.34, val loss: 0.205\n",
      "epoch 166 : 20/20 - accuracy: 89.81, loss:0.269, val accuracy: 96.23, val loss: 0.201\n",
      "epoch 167 : 20/20 - accuracy: 90.45, loss:0.27, val accuracy: 92.45, val loss: 0.209\n",
      "epoch 168 : 20/20 - accuracy: 88.54, loss:0.271, val accuracy: 92.45, val loss: 0.204\n",
      "epoch 169 : 20/20 - accuracy: 92.36, loss:0.26, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 170 : 20/20 - accuracy: 89.17, loss:0.266, val accuracy: 92.45, val loss: 0.2\n",
      "epoch 171 : 20/20 - accuracy: 91.08, loss:0.262, val accuracy: 94.34, val loss: 0.203\n",
      "epoch 172 : 20/20 - accuracy: 89.17, loss:0.263, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 173 : 20/20 - accuracy: 92.36, loss:0.26, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 174 : 20/20 - accuracy: 91.72, loss:0.261, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 175 : 20/20 - accuracy: 91.08, loss:0.264, val accuracy: 96.23, val loss: 0.205\n",
      "epoch 176 : 20/20 - accuracy: 90.45, loss:0.26, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 177 : 20/20 - accuracy: 90.45, loss:0.263, val accuracy: 96.23, val loss: 0.196\n",
      "epoch 178 : 20/20 - accuracy: 87.9, loss:0.27, val accuracy: 92.45, val loss: 0.203\n",
      "epoch 179 : 20/20 - accuracy: 92.36, loss:0.259, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 180 : 20/20 - accuracy: 92.36, loss:0.259, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 181 : 20/20 - accuracy: 91.08, loss:0.259, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 182 : 20/20 - accuracy: 89.81, loss:0.263, val accuracy: 96.23, val loss: 0.195\n",
      "epoch 183 : 20/20 - accuracy: 91.72, loss:0.259, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 184 : 20/20 - accuracy: 90.45, loss:0.263, val accuracy: 96.23, val loss: 0.194\n",
      "epoch 185 : 20/20 - accuracy: 89.81, loss:0.261, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 186 : 20/20 - accuracy: 89.81, loss:0.261, val accuracy: 94.34, val loss: 0.206\n",
      "epoch 187 : 20/20 - accuracy: 85.99, loss:0.283, val accuracy: 94.34, val loss: 0.214\n",
      "epoch 188 : 20/20 - accuracy: 91.72, loss:0.262, val accuracy: 96.23, val loss: 0.196\n",
      "epoch 189 : 20/20 - accuracy: 88.54, loss:0.263, val accuracy: 94.34, val loss: 0.195\n",
      "epoch 190 : 20/20 - accuracy: 90.45, loss:0.262, val accuracy: 92.45, val loss: 0.2\n",
      "epoch 191 : 20/20 - accuracy: 90.45, loss:0.268, val accuracy: 92.45, val loss: 0.202\n",
      "epoch 192 : 20/20 - accuracy: 91.72, loss:0.257, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 193 : 20/20 - accuracy: 91.08, loss:0.258, val accuracy: 94.34, val loss: 0.198\n",
      "epoch 194 : 20/20 - accuracy: 91.72, loss:0.26, val accuracy: 96.23, val loss: 0.192\n",
      "epoch 195 : 20/20 - accuracy: 89.81, loss:0.269, val accuracy: 96.23, val loss: 0.21\n",
      "epoch 196 : 20/20 - accuracy: 91.08, loss:0.259, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 197 : 20/20 - accuracy: 89.81, loss:0.261, val accuracy: 96.23, val loss: 0.185\n",
      "epoch 198 : 20/20 - accuracy: 91.08, loss:0.261, val accuracy: 96.23, val loss: 0.202\n",
      "epoch 199 : 20/20 - accuracy: 89.17, loss:0.274, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 200 : 20/20 - accuracy: 88.54, loss:0.288, val accuracy: 92.45, val loss: 0.23\n",
      "epoch 201 : 20/20 - accuracy: 92.36, loss:0.257, val accuracy: 94.34, val loss: 0.195\n",
      "epoch 202 : 20/20 - accuracy: 89.17, loss:0.258, val accuracy: 94.34, val loss: 0.187\n",
      "epoch 203 : 20/20 - accuracy: 92.36, loss:0.256, val accuracy: 94.34, val loss: 0.196\n",
      "epoch 204 : 20/20 - accuracy: 91.72, loss:0.257, val accuracy: 94.34, val loss: 0.198\n",
      "epoch 205 : 20/20 - accuracy: 91.08, loss:0.256, val accuracy: 94.34, val loss: 0.188\n",
      "epoch 206 : 20/20 - accuracy: 87.26, loss:0.277, val accuracy: 92.45, val loss: 0.228\n",
      "epoch 207 : 20/20 - accuracy: 89.81, loss:0.278, val accuracy: 94.34, val loss: 0.221\n",
      "epoch 208 : 20/20 - accuracy: 88.54, loss:0.277, val accuracy: 94.34, val loss: 0.198\n",
      "epoch 209 : 20/20 - accuracy: 91.08, loss:0.27, val accuracy: 94.34, val loss: 0.209\n",
      "epoch 210 : 20/20 - accuracy: 89.17, loss:0.301, val accuracy: 92.45, val loss: 0.235\n",
      "epoch 211 : 20/20 - accuracy: 91.72, loss:0.274, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 212 : 20/20 - accuracy: 91.72, loss:0.257, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 213 : 20/20 - accuracy: 91.72, loss:0.256, val accuracy: 94.34, val loss: 0.195\n",
      "epoch 214 : 20/20 - accuracy: 89.17, loss:0.265, val accuracy: 92.45, val loss: 0.199\n",
      "epoch 215 : 20/20 - accuracy: 91.72, loss:0.255, val accuracy: 94.34, val loss: 0.187\n",
      "epoch 216 : 20/20 - accuracy: 88.54, loss:0.261, val accuracy: 96.23, val loss: 0.186\n",
      "epoch 217 : 20/20 - accuracy: 91.72, loss:0.255, val accuracy: 94.34, val loss: 0.188\n",
      "epoch 218 : 20/20 - accuracy: 91.72, loss:0.266, val accuracy: 96.23, val loss: 0.199\n",
      "epoch 219 : 20/20 - accuracy: 87.26, loss:0.274, val accuracy: 92.45, val loss: 0.206\n",
      "epoch 220 : 20/20 - accuracy: 90.45, loss:0.257, val accuracy: 94.34, val loss: 0.2\n",
      "epoch 221 : 20/20 - accuracy: 89.81, loss:0.263, val accuracy: 96.23, val loss: 0.207\n",
      "epoch 222 : 20/20 - accuracy: 89.81, loss:0.264, val accuracy: 96.23, val loss: 0.206\n",
      "epoch 223 : 20/20 - accuracy: 91.72, loss:0.256, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 224 : 20/20 - accuracy: 91.72, loss:0.262, val accuracy: 96.23, val loss: 0.195\n",
      "epoch 225 : 20/20 - accuracy: 89.17, loss:0.26, val accuracy: 92.45, val loss: 0.195\n",
      "epoch 226 : 20/20 - accuracy: 90.45, loss:0.254, val accuracy: 94.34, val loss: 0.186\n",
      "epoch 227 : 20/20 - accuracy: 91.72, loss:0.255, val accuracy: 94.34, val loss: 0.198\n",
      "epoch 228 : 20/20 - accuracy: 89.81, loss:0.257, val accuracy: 94.34, val loss: 0.179\n",
      "epoch 229 : 20/20 - accuracy: 91.08, loss:0loss:0.254, val accuracy: 94.34, val loss: 0.183\n",
      "epoch 230 : 20/20 - accuracy: 92.36, loss:0.253, val accuracy: 94.34, val loss: 0.192\n",
      "epoch 231 : 20/20 - accuracy: 89.17, loss:0.273, val accuracy: 94.34, val loss: 0.22\n",
      "epoch 232 : 20/20 - accuracy: 89.81, loss:0.26, val accuracy: 96.23, val loss: 0.184\n",
      "epoch 233 : 20/20 - accuracy: 92.36, loss:0.253, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 234 : 20/20 - accuracy: 89.81, loss:0.254, val accuracy: 94.34, val loss: 0.187\n",
      "epoch 235 : 20/20 - accuracy: 90.45, loss:0.253, val accuracy: 94.34, val loss: 0.186\n",
      "epoch 236 : 20/20 - accuracy: 89.17, loss:0.255, val accuracy: 94.34, val loss: 0.181\n",
      "epoch 237 : 20/20 - accuracy: 91.08, loss:0.256, val accuracy: 96.23, val loss: 0.189\n",
      "epoch 238 : 20/20 - accuracy: 89.17, loss:0.257, val accuracy: 94.34, val loss: 0.185\n",
      "epoch 239 : 20/20 - accuracy: 90.45, loss:0.258, val accuracy: 96.23, val loss: 0.199\n",
      "epoch 240 : 20/20 - accuracy: 90.45, loss:0.257, val accuracy: 92.45, val loss: 0.202\n",
      "epoch 241 : 20/20 - accuracy: 89.81, loss:0.254, val accuracy: 94.34, val loss: 0.183\n",
      "epoch 242 : 20/20 - accuracy: 89.81, loss:0.257, val accuracy: 96.23, val loss: 0.189\n",
      "epoch 243 : 20/20 - accuracy: 88.54, loss:0.257, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 244 : 20/20 - accuracy: 91.08, loss:0.261, val accuracy: 96.23, val loss: 0.18\n",
      "epoch 245 : 20/20 - accuracy: 91.72, loss:0.252, val accuracy: 94.34, val loss: 0.19\n",
      "epoch 246 : 20/20 - accuracy: 91.72, loss:0.251, val accuracy: 94.34, val loss: 0.188\n",
      "epoch 247 : 20/20 - accuracy: 91.08, loss:0.271, val accuracy: 94.34, val loss: 0.211\n",
      "epoch 248 : 20/20 - accuracy: 89.81, loss:0.254, val accuracy: 94.34, val loss: 0.184\n",
      "epoch 249 : 20/20 - accuracy: 87.9, loss:0.261, val accuracy: 92.45, val loss: 0.191\n",
      "epoch 250 : 20/20 - accuracy: 90.45, loss:0.255, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 251 : 20/20 - accuracy: 91.08, loss:0.251, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 252 : 20/20 - accuracy: 87.9, loss:0.285, val accuracy: 92.45, val loss: 0.208\n",
      "epoch 253 : 20/20 - accuracy: 88.54, loss:0.257, val accuracy: 94.34, val loss: 0.186\n",
      "epoch 254 : 20/20 - accuracy: 89.81, loss:0.261, val accuracy: 96.23, val loss: 0.208\n",
      "epoch 255 : 20/20 - accuracy: 91.72, loss:0.253, val accuracy: 96.23, val loss: 0.191\n",
      "epoch 256 : 20/20 - accuracy: 91.72, loss:0.252, val accuracy: 94.34, val loss: 0.19\n",
      "epoch 257 : 20/20 - accuracy: 89.81, loss:0.268, val accuracy: 94.34, val loss: 0.214\n",
      "epoch 258 : 20/20 - accuracy: 91.72, loss:0.252, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 259 : 20/20 - accuracy: 89.17, loss:0.262, val accuracy: 92.45, val loss: 0.197\n",
      "epoch 260 : 20/20 - accuracy: 85.35, loss:0.284, val accuracy: 94.34, val loss: 0.215\n",
      "epoch 261 : 20/20 - accuracy: 91.08, loss:0.253, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 262 : 20/20 - accuracy: 91.08, loss:0.253, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 263 : 20/20 - accuracy: 88.54, loss:0.261, val accuracy: 92.45, val loss: 0.193\n",
      "epoch 264 : 20/20 - accuracy: 90.45, loss:0.253, val accuracy: 94.34, val loss: 0.197\n",
      "epoch 265 : 20/20 - accuracy: 92.36, loss:0.25, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 266 : 20/20 - accuracy: 91.72, loss:0.251, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 267 : 20/20 - accuracy: 89.81, loss:0.256, val accuracy: 96.23, val loss: 0.18\n",
      "epoch 268 : 20/20 - accuracy: 90.45, loss:0.25, val accuracy: 94.34, val loss: 0.179\n",
      "epoch 269 : 20/20 - accuracy: 86.62, loss:0.268, val accuracy: 94.34, val loss: 0.194\n",
      "epoch 270 : 20/20 - accuracy: 89.81, loss:0.252, val accuracy: 94.34, val loss: 0.182\n",
      "epoch 271 : 20/20 - accuracy: 90.45, loss:0.252, val accuracy: 94.34, val loss: 0.195\n",
      "epoch 272 : 20/20 - accuracy: 89.81, loss:0.254, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 273 : 20/20 - accuracy: 87.9, loss:0.258, val accuracy: 96.23, val loss: 0.179\n",
      "epoch 274 : 20/20 - accuracy: 90.45, loss:0.251, val accuracy: 94.34, val loss: 0.184\n",
      "epoch 275 : 20/20 - accuracy: 90.45, loss:0.258, val accuracy: 92.45, val loss: 0.203\n",
      "epoch 276 : 20/20 - accuracy: 88.54, loss:0.274, val accuracy: 94.34, val loss: 0.22\n",
      "epoch 277 : 20/20 - accuracy: 91.08, loss:0.263, val accuracy: 96.23, val loss: 0.201\n",
      "epoch 278 : 20/20 - accuracy: 92.36, loss:0.248, val accuracy: 94.34, val loss: 0.187\n",
      "epoch 279 : 20/20 - accuracy: 87.9, loss:0.263, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 280 : 20/20 - accuracy: 89.17, loss:0.251, val accuracy: 94.34, val loss: 0.199\n",
      "epoch 281 : 20/20 - accuracy: 89.17, loss:0.253, val accuracy: 94.34, val loss: 0.201\n",
      "epoch 282 : 20/20 - accuracy: 91.72, loss:0.251, val accuracy: 96.23, val loss: 0.19\n",
      "epoch 283 : 20/20 - accuracy: 88.54, loss:0.262, val accuracy: 92.45, val loss: 0.196\n",
      "epoch 284 : 20/20 - accuracy: 90.45, loss:0.261, val accuracy: 96.23, val loss: 0.188\n",
      "epoch 285 : 20/20 - accuracy: 89.81, loss:0.252, val accuracy: 96.23, val loss: 0.172\n",
      "epoch 286 : 20/20 - accuracy: 91.72, loss:0.248, val accuracy: 94.34, val loss: 0.181\n",
      "epoch 287 : 20/20 - accuracy: 89.81, loss:0.254, val accuracy: 94.34, val loss: 0.204\n",
      "epoch 288 : 20/20 - accuracy: 89.81, loss:0.257, val accuracy: 92.45, val loss: 0.194\n",
      "epoch 289 : 20/20 - accuracy: 91.72, loss:0.25, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 290 : 20/20 - accuracy: 89.81, loss:0.253, val accuracy: 96.23, val loss: 0.182\n",
      "epoch 291 : 20/20 - accuracy: 87.26, loss:0.262, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 292 : 20/20 - accuracy: 85.99, loss:0.27, val accuracy: 92.45, val loss: 0.204\n",
      "epoch 293 : 20/20 - accuracy: 89.17, loss:0.253, val accuracy: 96.23, val loss: 0.173\n",
      "epoch 294 : 20/20 - accuracy: 90.45, loss:0.248, val accuracy: 94.34, val loss: 0.176\n",
      "epoch 295 : 20/20 - accuracy: 91.72, loss:0.26, val accuracy: 96.23, val loss: 0.197\n",
      "epoch 296 : 20/20 - accuracy: 89.81, loss:0.252, val accuracy: 92.45, val loss: 0.188\n",
      "epoch 297 : 20/20 - accuracy: 90.45, loss:0.249, val accuracy: 94.34, val loss: 0.18\n",
      "epoch 298 : 20/20 - accuracy: 91.08, loss:0.249, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 299 : 20/20 - accuracy: 91.72, loss:0.256, val accuracy: 96.23, val loss: 0.193\n",
      "epoch 300 : 20/20 - accuracy: 87.9, loss:0.253, val accuracy: 92.45, val loss: 0.185\n",
      "epoch 301 : 20/20 - accuracy: 90.45, loss:0.253, val accuracy: 92.45, val loss: 0.193\n",
      "epoch 302 : 20/20 - accuracy: 89.81, loss:0.291, val accuracy: 92.45, val loss: 0.229\n",
      "epoch 303 : 20/20 - accuracy: 88.54, loss:0.272, val accuracy: 92.45, val loss: 0.213\n",
      "epoch 304 : 20/20 - accuracy: 90.45, loss:0.247, val accuracy: 94.34, val loss: 0.178\n",
      "epoch 305 : 20/20 - accuracy: 89.81, loss:0.252, val accuracy: 96.23, val loss: 0.18\n",
      "epoch 306 : 20/20 - accuracy: 87.9, loss:0.256, val accuracy: 92.45, val loss: 0.188\n",
      "epoch 307 : 20/20 - accuracy: 91.08, loss:0.246, val accuracy: 94.34, val loss: 0.177\n",
      "epoch 308 : 20/20 - accuracy: 91.72, loss:0.246, val accuracy: 94.34, val loss: 0.188\n",
      "epoch 309 : 20/20 - accuracy: 91.08, loss:0.249, val accuracy: 94.34, val loss: 0.195\n",
      "epoch 310 : 20/20 - accuracy: 87.9, loss:0.259, val accuracy: 92.45, val loss: 0.193\n",
      "epoch 311 : 20/20 - accuracy: 90.45, loss:0.247, val accuracy: 94.34, val loss: 0.181\n",
      "epoch 312 : 20/20 - accuracy: 87.26, loss:0.257, val accuracy: 94.34, val loss: 0.185\n",
      "epoch 313 : 20/20 - accuracy: 87.9, loss:0.275, val accuracy: 94.34, val loss: 0.199\n",
      "epoch 314 : 20/20 - accuracy: 92.36, loss:0.246, val accuracy: 94.34, val loss: 0.186\n",
      "epoch 315 : 20/20 - accuracy: 87.9, loss:0.251, val accuracy: 92.45, val loss: 0.184\n",
      "epoch 316 : 20/20 - accuracy: 91.72, loss:0.245, val accuracy: 94.34, val loss: 0.185\n",
      "epoch 317 : 20/20 - accuracy: 87.9, loss:0.257, val accuracy: 92.45, val loss: 0.187\n",
      "epoch 318 : 20/20 - accuracy: 91.08, loss:0.246, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 319 : 20/20 - accuracy: 88.54, loss:0.275, val accuracy: 92.45, val loss: 0.222\n",
      "epoch 320 : 20/20 - accuracy: 90.45, loss:0.259, val accuracy: 96.23, val loss: 0.201\n",
      "epoch 321 : 20/20 - accuracy: 89.17, loss:0.279, val accuracy: 92.45, val loss: 0.219\n",
      "epoch 322 : 20/20 - accuracy: 87.9, loss:0.256, val accuracy: 94.34, val loss: 0.187\n",
      "epoch 323 : 20/20 - accuracy: 92.36, loss:0.244, val accuracy: 94.34, val loss: 0.184\n",
      "epoch 324 : 20/20 - accuracy: 89.81, loss:0.249, val accuracy: 94.34, val loss: 0.193\n",
      "epoch 325 : 20/20 - accuracy: 89.17, loss:0.253, val accuracy: 92.45, val loss: 0.207\n",
      "epoch 326 : 20/20 - accuracy: 91.72, loss:0.248, val accuracy: 96.23, val loss: 0.189\n",
      "epoch 327 : 20/20 - accuracy: 90.45, loss:0.246, val accuracy: 94.34, val loss: 0.178\n",
      "epoch 328 : 20/20 - accuracy: 88.54, loss:0.25, val accuracy: 96.23, val loss: 0.179\n",
      "epoch 329 : 20/20 - accuracy: 91.08, loss:0.245, val accuracy: 94.34, val loss: 0.188\n",
      "epoch 330 : 20/20 - accuracy: 92.36, loss:0.244, val accuracy: 94.34, val loss: 0.182\n",
      "epoch 331 : 20/20 - accuracy: 91.08, loss:0.244, val accuracy: 94.34, val loss: 0.177\n",
      "epoch 332 : 20/20 - accuracy: 91.72, loss:0.244, val accuracy: 94.34, val loss: 0.184\n",
      "epoch 333 : 20/20 - accuracy: 91.08, loss:0.245, val accuracy: 94.34, val loss: 0.189\n",
      "epoch 334 : 20/20 - accuracy: 88.54, loss:0.259, val accuracy: 92.45, val loss: 0.194\n",
      "epoch 335 : 20/20 - accuracy: 91.72, loss:0.248, val accuracy: 96.23, val loss: 0.183\n",
      "epoch 336 : 20/20 - accuracy: 91.08, loss:0.245, val accuracy: 94.34, val loss: 0.191\n",
      "epoch 337 : 20/20 - accuracy: 91.72, loss:0.244, val accuracy: 94.34, val loss: 0.179\n",
      "epoch 338 : 20/20 - accuracy: 91.72, loss:0.245, val accuracy: 92.45, val loss: 0.188\n",
      "epoch 339 : 20/20 - accuracy: 91.08, loss:0.244, val accuracy: 94.34, val loss: 0.181\n",
      "epoch 340 : 20/20 - accuracy: 91.72, loss:0.243, val accuracy: 94.34, val loss: 0.184\n",
      "epoch 341 : 20/20 - accuracy: 87.9, loss:0.286, val accuracy: 92.45, val loss: 0.234\n",
      "epoch 342 : 20/20 - accuracy: 89.81, loss:0.252, val accuracy: 98.11, val loss: 0.172\n",
      "epoch 343 : 20/20 - accuracy: 91.72, loss:0.255, val accuracy: 96.23, val loss: 0.194\n",
      "epoch 344 : 20/20 - accuracy: 89.17, loss:0.244, val accuracy: 94.34, val loss: 0.171\n",
      "epoch 345 : 20/20 - accuracy: 91.08, loss:0.243, val accuracy: 94.34, val loss: 0.176\n",
      "epoch 346 : 20/20 - accuracy: 89.17, loss:0.25, val accuracy: 92.45, val loss: 0.187\n",
      "epoch 347 : 20/20 - accuracy: 91.72, loss:0.244, val accuracy: 94.34, val loss: 0.181\n",
      "epoch 348 : 20/20 - accuracy: 85.35, loss:0.277, val accuracy: 94.34, val loss: 0.208\n",
      "epoch 349 : 20/20 - accuracy: 91.72, loss:0.243, val accuracy: 94.34, val loss: 0.181\n"
     ]
    }
   ],
   "source": [
    "myModel.fit(data_train, data_val, batch_size=8, epochs=350, loss=\"sparseCategoricalCrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6667242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(myModel.predict(data_train[:,:-1]), axis=1) == data_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9caf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 2., 0., 1., 2., 2., 1., 0., 1., 2., 0., 2., 1., 0., 0., 2.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 2., 0., 0., 0., 0., 1., 2., 0., 2., 2.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 2., 0., 1., 1., 2., 0., 2.,\n",
       "       2., 0., 1., 1., 0., 0., 2., 2., 2., 1., 2., 1., 2., 1., 2., 2., 2.,\n",
       "       2., 0., 1., 1., 1., 1., 2., 1., 2., 0., 1., 2., 2., 0., 0., 2., 2.,\n",
       "       1., 0., 1., 1., 0., 2., 0., 0., 0., 0., 0., 1., 0., 1., 2., 1., 0.,\n",
       "       1., 2., 2., 1., 0., 1., 2., 1., 2., 0., 1., 2., 2., 2., 0., 0., 1.,\n",
       "       0., 1., 2., 2., 2., 1., 1., 2., 2., 1., 0., 0., 2., 2., 0., 1., 2.,\n",
       "       0., 2., 0., 1., 0., 2., 2., 1., 0., 1., 1., 1., 2., 1., 2., 0., 0.,\n",
       "       2., 0., 1., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f854de57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.79377638e-04, 8.71692897e-02, 7.80683794e-04, 4.41164861e-03,\n",
       "       9.48791838e-01, 9.68229007e-04, 5.58161855e-03, 9.37818084e-01,\n",
       "       3.28447136e-01, 9.45269698e-01, 6.86666562e-04, 3.45742307e-02,\n",
       "       1.24838790e-02, 7.09408966e-01, 2.66808354e-02, 8.63147388e-01,\n",
       "       2.26714776e-03, 1.59680045e-01, 9.53918838e-01, 4.88285514e-02,\n",
       "       9.28853951e-01, 3.26996101e-03, 9.14464602e-01, 4.04573125e-02,\n",
       "       6.43471881e-04, 2.89363247e-02, 6.30525580e-02, 2.58004548e-01,\n",
       "       2.03683707e-02, 8.97066100e-01, 8.71826635e-04, 2.68630650e-02,\n",
       "       6.41591768e-03, 1.57510463e-03, 1.19642766e-01, 9.43908220e-01,\n",
       "       8.42844727e-02, 9.42072469e-01, 2.94480449e-01, 9.53585025e-01,\n",
       "       9.44929190e-01, 8.86983544e-01, 8.17877825e-01, 9.39756433e-01,\n",
       "       2.55306419e-03, 8.44285766e-02, 8.92910805e-01, 7.29787385e-01,\n",
       "       1.21249421e-03, 8.56523513e-02, 7.10382355e-04, 7.19832018e-04,\n",
       "       7.47984677e-02, 8.64852758e-01, 1.10921885e-01, 3.63250235e-02,\n",
       "       7.23610068e-02, 7.69664832e-04, 1.01264600e-03, 2.25087869e-03,\n",
       "       9.44387322e-01, 7.46440223e-04, 8.57174796e-01, 7.81660701e-04,\n",
       "       9.40250036e-01, 6.91997077e-04, 3.62029636e-03, 6.88698743e-04,\n",
       "       6.23194591e-03, 4.30723751e-03, 9.40247964e-01, 8.74388543e-01,\n",
       "       9.45428920e-01, 9.50179992e-01, 7.80840828e-04, 8.50610964e-01,\n",
       "       7.12656213e-04, 1.27988382e-02, 8.76478437e-01, 2.27968402e-03,\n",
       "       1.57285771e-03, 5.62862558e-02, 5.79332875e-02, 1.81160030e-02,\n",
       "       8.67897125e-04, 9.36701840e-01, 1.71066529e-02, 8.75320246e-01,\n",
       "       9.48038180e-01, 1.10384844e-01, 6.35456738e-04, 2.11305354e-01,\n",
       "       2.78201251e-02, 3.86040112e-01, 3.53602134e-02, 2.31243521e-02,\n",
       "       9.44485042e-01, 1.10337806e-01, 9.49766322e-01, 7.07147209e-04,\n",
       "       9.25964932e-01, 7.20062736e-01, 7.72719426e-01, 7.84629173e-04,\n",
       "       1.02156199e-03, 8.69801190e-01, 2.65883935e-02, 9.53634674e-01,\n",
       "       1.63084926e-03, 9.49079993e-01, 6.80319331e-03, 9.52157421e-03,\n",
       "       9.51319510e-01, 1.24845989e-02, 7.53769331e-04, 9.67192368e-04,\n",
       "       8.03386354e-02, 6.31968904e-02, 9.52701467e-01, 7.99340925e-02,\n",
       "       8.41902471e-01, 5.35065087e-03, 9.41324684e-04, 7.33711672e-04,\n",
       "       9.25435398e-01, 8.89071371e-01, 6.84214498e-04, 1.82668308e-03,\n",
       "       8.76442625e-01, 3.87445078e-01, 7.30253423e-03, 7.49030202e-04,\n",
       "       1.34063933e-03, 3.26964768e-02, 8.65917481e-01, 1.68572747e-02,\n",
       "       1.19277715e-02, 8.18955506e-04, 2.08022516e-01, 6.67468928e-01,\n",
       "       1.89318048e-02, 7.20698523e-04, 1.20412770e-02, 1.37110835e-01,\n",
       "       8.62172632e-03, 4.42219589e-01, 9.25898003e-01, 9.36844769e-01,\n",
       "       6.70077305e-04, 9.11534652e-01, 6.41919218e-04, 1.67961274e-02,\n",
       "       1.88286081e-01, 8.17622447e-04, 2.75676545e-02, 9.34501917e-01,\n",
       "       9.96715663e-04])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binaryCrossentropyLoss(myModel,data_train[:,:-1], data_train[:, -1])\n",
    "f_tab = myModel.predict(data_train[:,:-1])\n",
    "y_pred = f_tab[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c97eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = setLossFunction(\"binaryCrossentropy\")\n",
    "lossTrain = []\n",
    "lossVal = []\n",
    "X_val = data_val[:, :-1]\n",
    "y_val = data_val[:, -1]\n",
    "# assert batch_size > 0, \"batch_size need to be > 0\"\n",
    "nb_batch = int(len(data_train) / batch_size)  + 1\n",
    "if len(data_train) % batch_size == 0:\n",
    "    nb_batch = nb_batch - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a8aba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f40121f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "data = data_train.copy()\n",
    "np.random.shuffle(data)\n",
    "X_train = data[:, :-1]\n",
    "y_train = data[:, -1]\n",
    "X_batchs = [X_train[i:i+batch_size] for i in range(0, len(X_train), batch_size)]\n",
    "y_batchs = [y_train[i:i+batch_size] for i in range(0, len(y_train), batch_size)]\n",
    "num_batch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a42f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67406175, 0.05008242, 0.27585583],\n",
       "       [0.65909509, 0.05185414, 0.28905077],\n",
       "       [0.70495815, 0.04588015, 0.2491617 ],\n",
       "       [0.66895014, 0.05102814, 0.28002172],\n",
       "       [0.72875896, 0.04309287, 0.22814817],\n",
       "       [0.71140395, 0.0451014 , 0.24349465],\n",
       "       [0.71691427, 0.04475614, 0.23832959],\n",
       "       [0.71389198, 0.04489398, 0.24121404]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for X_batch, y_batch in zip(X_batchs, y_batchs):\n",
    "X_batch = X_batchs[0]\n",
    "y_batch = y_batchs[0]\n",
    "num_batch += 1\n",
    "# self.back_propag(X_batch, y_batch, alpha)\n",
    "myModel.predict(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52e9bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.layers[-1].setErrorLastLayer(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6302f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "previousLayer = myModel.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3fe0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "# myModel.layers[i].setError(previousLayer) ==> erreur\n",
    "curentLayer = myModel.layers[i]\n",
    "curentLayer.errors = previousLayer.delta @ previousLayer.W.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "777d8b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14914498,  0.09778302, -0.22836575,  0.25271304,  0.15099635,\n",
       "        -0.02988386,  0.05476367, -0.05494796],\n",
       "       [-0.14704088,  0.09519577, -0.22475397,  0.25407174,  0.1468891 ,\n",
       "        -0.02745019,  0.0559438 , -0.05311208],\n",
       "       [ 0.04330027, -0.04839115,  0.0705633 ,  0.00874016, -0.07497661,\n",
       "         0.03962655,  0.01565427,  0.03082548],\n",
       "       [-0.1484485 ,  0.09694154, -0.2271391 ,  0.25309273,  0.14963501,\n",
       "        -0.02906436,  0.05514303, -0.05430932],\n",
       "       [-0.09687332,  0.12054808, -0.16178471, -0.06965247,  0.1878146 ,\n",
       "        -0.10906663, -0.05486738, -0.07969164],\n",
       "       [ 0.04228864, -0.04721246,  0.06903429,  0.0083053 , -0.07324483,\n",
       "         0.03876654,  0.01525914,  0.03022875],\n",
       "       [-0.09556474,  0.11926453, -0.1590151 , -0.07029484,  0.18533406,\n",
       "        -0.10741647, -0.05443456, -0.07806496],\n",
       "       [ 0.04190365, -0.04675598,  0.0684507 ,  0.00810733, -0.07257343,\n",
       "         0.03842696,  0.01509627,  0.02999572]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curentLayer.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "259f3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21730289,  0.78066008,  0.40182529],\n",
       "       [ 0.17088151, -0.59579319, -0.59583497],\n",
       "       [-0.76542164,  0.63423569,  0.17513634],\n",
       "       [ 0.36039228, -0.83037201,  0.81390774],\n",
       "       [ 0.57580754, -0.49824328, -0.55109532],\n",
       "       [-0.54835947, -0.33906238,  0.0428794 ],\n",
       "       [-0.11787469, -0.36160174,  0.1937349 ],\n",
       "       [-0.62441495, -0.36001603, -0.23146808]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousLayer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb89baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16702869, -0.17461135,  0.05839091],\n",
       "       [ 0.16294439, -0.1747633 ,  0.06171373],\n",
       "       [-0.07339575,  0.00837987,  0.05178699],\n",
       "       [ 0.16563736, -0.17464567,  0.05943847],\n",
       "       [ 0.18169531,  0.00783219, -0.15804055],\n",
       "       [-0.07184058,  0.00822677,  0.05040789],\n",
       "       [ 0.17855838,  0.00815633, -0.15711009],\n",
       "       [-0.07123883,  0.00818526,  0.04985585]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousLayer.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a695b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.98  , 15.85  ,  0.8993,  5.979 ,  3.687 ,  2.257 ,  5.919 ],\n",
       "       [19.15  , 16.45  ,  0.889 ,  6.245 ,  3.815 ,  3.084 ,  6.185 ],\n",
       "       [14.11  , 14.18  ,  0.882 ,  5.541 ,  3.221 ,  2.754 ,  5.038 ],\n",
       "       [20.1   , 16.99  ,  0.8746,  6.581 ,  3.785 ,  1.955 ,  6.449 ],\n",
       "       [10.82  , 12.83  ,  0.8256,  5.18  ,  2.63  ,  4.853 ,  5.089 ],\n",
       "       [14.01  , 14.29  ,  0.8625,  5.609 ,  3.158 ,  2.217 ,  5.132 ],\n",
       "       [11.02  , 13.    ,  0.8189,  5.325 ,  2.701 ,  6.735 ,  5.163 ],\n",
       "       [13.02  , 13.76  ,  0.8641,  5.395 ,  3.026 ,  3.373 ,  4.825 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curentLayer.input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "390e671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21730289,  0.78066008,  0.40182529],\n",
       "       [ 0.17088151, -0.59579319, -0.59583497],\n",
       "       [-0.76542164,  0.63423569,  0.17513634],\n",
       "       [ 0.36039228, -0.83037201,  0.81390774],\n",
       "       [ 0.57580754, -0.49824328, -0.55109532],\n",
       "       [-0.54835947, -0.33906238,  0.0428794 ],\n",
       "       [-0.11787469, -0.36160174,  0.1937349 ],\n",
       "       [-0.62441495, -0.36001603, -0.23146808]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousLayer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e8a49eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.33214780e-03, 1.00000000e+00, 3.21363874e-02, 1.00000000e+00,\n",
       "        8.79628652e-01, 7.93633979e-11, 3.91080295e-10, 9.65381654e-01],\n",
       "       [1.01196199e-03, 1.00000000e+00, 1.88335967e-02, 1.00000000e+00,\n",
       "        8.11105924e-01, 3.12075169e-11, 9.17015848e-11, 9.78840967e-01],\n",
       "       [4.15574496e-03, 9.99999998e-01, 7.13478848e-03, 9.99999999e-01,\n",
       "        9.29364239e-01, 2.86598608e-09, 1.40023647e-08, 7.91924487e-01],\n",
       "       [2.02647936e-03, 1.00000000e+00, 4.59852386e-02, 1.00000000e+00,\n",
       "        8.77505071e-01, 8.59294792e-12, 5.07411263e-11, 9.84141217e-01],\n",
       "       [2.71468476e-03, 9.99999878e-01, 7.33108490e-04, 9.99999999e-01,\n",
       "        9.56302814e-01, 2.03907471e-07, 1.72834378e-07, 5.78050479e-01],\n",
       "       [6.69917540e-03, 9.99999998e-01, 9.74520796e-03, 9.99999999e-01,\n",
       "        9.55002550e-01, 2.63262649e-09, 1.74626333e-08, 7.73481411e-01],\n",
       "       [6.76259882e-04, 9.99999910e-01, 1.42038870e-04, 1.00000000e+00,\n",
       "        9.07241479e-01, 2.57233545e-07, 7.38079397e-08, 5.94787245e-01],\n",
       "       [3.75562015e-03, 9.99999993e-01, 2.91618566e-03, 9.99999999e-01,\n",
       "        9.31164862e-01, 9.78952093e-09, 3.10455215e-08, 6.93270090e-01]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curentLayer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d581d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14914498,  0.09778302, -0.22836575,  0.25271304,  0.15099635,\n",
       "        -0.02988386,  0.05476367, -0.05494796],\n",
       "       [-0.14704088,  0.09519577, -0.22475397,  0.25407174,  0.1468891 ,\n",
       "        -0.02745019,  0.0559438 , -0.05311208],\n",
       "       [ 0.04330027, -0.04839115,  0.0705633 ,  0.00874016, -0.07497661,\n",
       "         0.03962655,  0.01565427,  0.03082548],\n",
       "       [-0.1484485 ,  0.09694154, -0.2271391 ,  0.25309273,  0.14963501,\n",
       "        -0.02906436,  0.05514303, -0.05430932],\n",
       "       [-0.09687332,  0.12054808, -0.16178471, -0.06965247,  0.1878146 ,\n",
       "        -0.10906663, -0.05486738, -0.07969164],\n",
       "       [ 0.04228864, -0.04721246,  0.06903429,  0.0083053 , -0.07324483,\n",
       "         0.03876654,  0.01525914,  0.03022875],\n",
       "       [-0.09556474,  0.11926453, -0.1590151 , -0.07029484,  0.18533406,\n",
       "        -0.10741647, -0.05443456, -0.07806496],\n",
       "       [ 0.04190365, -0.04675598,  0.0684507 ,  0.00810733, -0.07257343,\n",
       "         0.03842696,  0.01509627,  0.02999572]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousLayer.delta @ previousLayer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5baf046e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.16555962e-02, 6.79377638e-04, 9.67665026e-01],\n",
       "       [8.09320701e-01, 8.71692897e-02, 1.03510009e-01],\n",
       "       [3.26573893e-02, 7.80683794e-04, 9.66561927e-01],\n",
       "       [2.82293280e-01, 4.41164861e-03, 7.13295072e-01],\n",
       "       [5.05490964e-02, 9.48791838e-01, 6.59065822e-04],\n",
       "       [4.42198322e-02, 9.68229007e-04, 9.54811939e-01],\n",
       "       [3.10610207e-01, 5.58161855e-03, 6.83808174e-01],\n",
       "       [6.14958192e-02, 9.37818084e-01, 6.86096770e-04],\n",
       "       [6.53599415e-01, 3.28447136e-01, 1.79534487e-02],\n",
       "       [5.41261507e-02, 9.45269698e-01, 6.04151364e-04],\n",
       "       [3.39221530e-02, 6.86666562e-04, 9.65391180e-01],\n",
       "       [8.22914131e-01, 3.45742307e-02, 1.42511638e-01],\n",
       "       [8.35212397e-02, 1.24838790e-02, 9.03994881e-01],\n",
       "       [2.84343469e-01, 7.09408966e-01, 6.24756490e-03],\n",
       "       [8.22238129e-01, 2.66808354e-02, 1.51081036e-01],\n",
       "       [1.34951163e-01, 8.63147388e-01, 1.90144905e-03],\n",
       "       [8.36345159e-02, 2.26714776e-03, 9.14098336e-01],\n",
       "       [7.42909689e-01, 1.59680045e-01, 9.74102660e-02],\n",
       "       [4.55661991e-02, 9.53918838e-01, 5.14963043e-04],\n",
       "       [8.69539248e-01, 4.88285514e-02, 8.16322009e-02],\n",
       "       [7.03116832e-02, 9.28853951e-01, 8.34365632e-04]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.predict(data_train[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66fbad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.19  , 13.05  ,  0.8253,  5.25  ,  2.675 ,  5.813 ,  5.219 ],\n",
       "       [14.69  , 14.49  ,  0.8799,  5.563 ,  3.259 ,  3.586 ,  5.219 ],\n",
       "       [11.14  , 12.79  ,  0.8558,  5.011 ,  2.794 ,  6.388 ,  5.049 ],\n",
       "       [11.42  , 12.86  ,  0.8683,  5.008 ,  2.85  ,  2.7   ,  4.607 ],\n",
       "       [19.14  , 16.61  ,  0.8722,  6.259 ,  3.737 ,  6.682 ,  6.053 ],\n",
       "       [12.19  , 13.36  ,  0.8579,  5.24  ,  2.909 ,  4.857 ,  5.158 ],\n",
       "       [12.62  , 13.67  ,  0.8481,  5.41  ,  2.911 ,  3.306 ,  5.231 ],\n",
       "       [18.81  , 16.29  ,  0.8906,  6.272 ,  3.693 ,  3.237 ,  6.053 ],\n",
       "       [16.44  , 15.25  ,  0.888 ,  5.884 ,  3.505 ,  1.969 ,  5.533 ],\n",
       "       [18.89  , 16.23  ,  0.9008,  6.227 ,  3.769 ,  3.639 ,  5.966 ],\n",
       "       [10.8   , 12.57  ,  0.859 ,  4.981 ,  2.821 ,  4.773 ,  5.063 ],\n",
       "       [14.11  , 14.26  ,  0.8722,  5.52  ,  3.168 ,  2.688 ,  5.219 ],\n",
       "       [12.7   , 13.41  ,  0.8874,  5.183 ,  3.091 ,  8.456 ,  5.    ],\n",
       "       [16.23  , 15.18  ,  0.885 ,  5.872 ,  3.472 ,  3.769 ,  5.922 ],\n",
       "       [14.01  , 14.29  ,  0.8625,  5.609 ,  3.158 ,  2.217 ,  5.132 ],\n",
       "       [17.08  , 15.38  ,  0.9079,  5.832 ,  3.683 ,  2.956 ,  5.484 ],\n",
       "       [12.8   , 13.47  ,  0.886 ,  5.16  ,  3.126 ,  4.873 ,  4.914 ],\n",
       "       [14.59  , 14.28  ,  0.8993,  5.351 ,  3.333 ,  4.185 ,  4.781 ],\n",
       "       [20.24  , 16.91  ,  0.8897,  6.315 ,  3.962 ,  5.901 ,  6.188 ],\n",
       "       [15.01  , 14.76  ,  0.8657,  5.789 ,  3.245 ,  1.791 ,  5.001 ],\n",
       "       [18.14  , 16.12  ,  0.8772,  6.059 ,  3.563 ,  3.619 ,  6.011 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d017cb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MySequencial.MySequencial at 0x7fb2c3a7cf40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "933e80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(myModel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8673b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56a68ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52385216,  1.08944542,  0.2442697 ,  0.38665219, -0.38420246,\n",
       "        -0.64359113, -0.79639527,  0.5914137 ],\n",
       "       [ 0.37115738,  0.32134918, -0.68525358,  0.8679324 ,  0.47645947,\n",
       "        -0.29638172, -0.47612836, -0.5848817 ],\n",
       "       [-0.37679555, -0.3125585 , -1.3671208 , -2.09166546,  2.22156596,\n",
       "        -1.11600502, -1.81964792, -0.63243539],\n",
       "       [ 0.11993206,  0.45489615, -0.37506173,  0.07867955,  0.06071849,\n",
       "        -0.58370932,  0.26124022, -0.60719116],\n",
       "       [-1.90683955,  2.32174721,  1.07414983,  2.56149343, -0.89586472,\n",
       "        -0.41545526,  1.34376972, -0.0199011 ],\n",
       "       [-0.65464892, -0.00835384, -0.80646254,  0.70896396, -0.41780563,\n",
       "         0.28149695, -0.32612578,  0.03475889],\n",
       "       [ 0.08090457, -0.54584805,  0.81334457,  0.47654429,  0.76123428,\n",
       "         0.6838611 ,  0.16956792,  0.73070765],\n",
       "       [ 0.10943854, -1.70394873, -1.31113899, -1.9791037 ,  0.72289348,\n",
       "        -0.57924754, -0.47287431, -0.44287366]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.layers[2].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f76e27b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52385216,  1.08944542,  0.2442697 ,  0.38665219, -0.38420246,\n",
       "        -0.64359113, -0.79639527,  0.5914137 ],\n",
       "       [ 0.37115738,  0.32134918, -0.68525358,  0.8679324 ,  0.47645947,\n",
       "        -0.29638172, -0.47612836, -0.5848817 ],\n",
       "       [-0.37679555, -0.3125585 , -1.3671208 , -2.09166546,  2.22156596,\n",
       "        -1.11600502, -1.81964792, -0.63243539],\n",
       "       [ 0.11993206,  0.45489615, -0.37506173,  0.07867955,  0.06071849,\n",
       "        -0.58370932,  0.26124022, -0.60719116],\n",
       "       [-1.90683955,  2.32174721,  1.07414983,  2.56149343, -0.89586472,\n",
       "        -0.41545526,  1.34376972, -0.0199011 ],\n",
       "       [-0.65464892, -0.00835384, -0.80646254,  0.70896396, -0.41780563,\n",
       "         0.28149695, -0.32612578,  0.03475889],\n",
       "       [ 0.08090457, -0.54584805,  0.81334457,  0.47654429,  0.76123428,\n",
       "         0.6838611 ,  0.16956792,  0.73070765],\n",
       "       [ 0.10943854, -1.70394873, -1.31113899, -1.9791037 ,  0.72289348,\n",
       "        -0.57924754, -0.47287431, -0.44287366]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.layers[2].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038271e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
